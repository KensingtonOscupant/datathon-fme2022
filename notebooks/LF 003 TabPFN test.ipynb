{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from haversine import haversine, Unit\n",
    "import xgboost\n",
    "from tabpfn.scripts import transformer_prediction_interface\n",
    "from sklearn import preprocessing\n",
    "from sklearn import pipeline\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import neighbors\n",
    "from sklearn import neural_network\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(context='paper', font_scale=1.15)\n",
    "\n",
    "data_dir = '../data/datathon_SC_ACN_22/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_data = pd.read_csv(data_dir + 'orders.csv', delimiter=';', index_col='order_id')\n",
    "cities_data = pd.read_csv(data_dir + 'cities_data.csv', delimiter=';')\n",
    "product_data = pd.read_csv(data_dir + 'product_attributes.csv', delimiter=',', index_col='product_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### City coordinate extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_data1 = cities_data[['city_from_name', 'city_from_coord']]\n",
    "cities_data2 = cities_data[['city_to_name', 'city_to_coord']]\n",
    "cities_data1 = cities_data1.rename(columns={'city_from_name': 'city_name', 'city_from_coord': 'city_coord'})\n",
    "cities_data2 = cities_data2.rename(columns={'city_to_name': 'city_name', 'city_to_coord': 'city_coord'})\n",
    "\n",
    "cities_data = pd.concat([cities_data1, cities_data2]).drop_duplicates().set_index('city_name')\n",
    "\n",
    "# Transform lat long tuple as string to two columns\n",
    "cities_data['lat'] = cities_data['city_coord'].apply(lambda x: float(x[1:-1].split(',')[0]))\n",
    "cities_data['long'] = cities_data['city_coord'].apply(lambda x: float(x[1:-1].split(',')[1]))\n",
    "cities_data = cities_data.drop(columns=['city_coord'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "\n",
    "- Lat long for all three locations\n",
    "- Distance on water\n",
    "- Distance on land\n",
    "- Distance on land **log**\n",
    "- Distance on land **sqr**\n",
    "- Units\n",
    "- Units **log**\n",
    "- Units **sqr**\n",
    "- Third party **ONH**\n",
    "- Customs **ONH**\n",
    "- Material handling **ONH**\n",
    "- Weight\n",
    "- Weight **log**\n",
    "- Weight **sqr**\n",
    "- Weight percent deviation from mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace ATHENAS with Athens and BCN with Barcelona in the origin_port column\n",
    "orders_data['origin_port'] = orders_data['origin_port'].replace('ATHENAS', 'Athens')\n",
    "orders_data['origin_port'] = orders_data['origin_port'].replace('BCN', 'Barcelona')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Order coordinate mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only for those extracted columns\n",
    "city_lat_longs = cities_data[['lat', 'long']].drop_duplicates()\n",
    "\n",
    "# Add to order df\n",
    "orders_data = orders_data.join(city_lat_longs.rename(columns={'lat': 'start_lat', 'long': 'start_long'}), on='origin_port')\n",
    "orders_data = orders_data.join(city_lat_longs.rename(columns={'lat': 'hub_lat', 'long': 'hub_long'}), on='logistic_hub')\n",
    "orders_data = orders_data.join(city_lat_longs.rename(columns={'lat': 'end_lat', 'long': 'end_long'}), on='customer')\n",
    "\n",
    "orders_data.loc[orders_data['logistic_hub'].isna(), 'hub_lat'] = orders_data.loc[orders_data['logistic_hub'].isna(), 'start_lat']\n",
    "orders_data.loc[orders_data['logistic_hub'].isna(), 'hub_long'] = orders_data.loc[orders_data['logistic_hub'].isna(), 'start_long']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shippment distance calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances\n",
    "orders_data['distance_on_water'] = orders_data.apply(lambda x: haversine((x['start_lat'], x['start_long']), (x['hub_lat'], x['hub_long'])), axis=1)\n",
    "orders_data['distance_on_land'] = orders_data.apply(lambda x: haversine((x['hub_lat'], x['hub_long']), (x['end_lat'], x['end_long'])), axis=1)\n",
    "\n",
    "# Handle no hub orders\n",
    "# if hub == nan then replace sea_distance with 0\n",
    "orders_data['distance_on_water'] = orders_data['distance_on_water'].fillna(0)\n",
    "orders_data.loc[orders_data['logistic_hub'].isna(), 'distance_on_land'] = orders_data.loc[orders_data['logistic_hub'].isna()].apply(lambda x: haversine((x['start_lat'], x['start_long']), (x['end_lat'], x['end_long'])), axis=1)\n",
    "\n",
    "# Log version of distance on land\n",
    "orders_data['distance_on_land_log'] = orders_data['distance_on_land'].apply(lambda x: np.log(x))\n",
    "\n",
    "# No distance on land err handling\n",
    "orders_data.loc[orders_data['distance_on_land'] == 0, 'distance_on_land_log'] = 0\n",
    "\n",
    "# Add distance on land squared\n",
    "orders_data['distance_on_land_squared'] = orders_data['distance_on_land'] ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Order product volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log version of units of order\n",
    "orders_data['units_log'] = orders_data['units'].apply(lambda x: np.log(x))\n",
    "\n",
    "# Units squared\n",
    "orders_data['units_squared'] = orders_data['units'] ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Product weight information and material handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join product data\n",
    "orders_data = orders_data.join(product_data, on='product_id')\n",
    "\n",
    "# Log version of product weight\n",
    "orders_data['weight_log'] = orders_data['weight'].apply(lambda x: np.log(x))\n",
    "\n",
    "# Add squared version of weight and units\n",
    "orders_data['weight_squared'] = orders_data['weight'] ** 2\n",
    "\n",
    "# Relative deviation from mean weight\n",
    "orders_data['weight_deviation'] = (orders_data['weight'] - orders_data['weight'].mean()).abs()\n",
    "\n",
    "# Convert material handling class as int to string class\n",
    "orders_data['material_handling'] = orders_data['material_handling'].apply(lambda x: \"c\" + str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop incomplete samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nas, which in this case should only be products without information\n",
    "orders_data = orders_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One-hot-encode categorical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_data = orders_data.sample(n=1024)\n",
    "\n",
    "orders_features = orders_data.drop(columns=['origin_port', 'logistic_hub', 'customer', 'late_order', 'product_id'])\n",
    "\n",
    "orders_features = pd.get_dummies(orders_features)\n",
    "orders_target = orders_data['late_order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['units', 'start_lat', 'start_long', 'hub_lat', 'hub_long', 'end_lat',\n",
       "       'end_long', 'distance_on_water', 'distance_on_land',\n",
       "       'distance_on_land_log', 'distance_on_land_squared', 'units_log',\n",
       "       'units_squared', 'weight', 'weight_log', 'weight_squared',\n",
       "       'weight_deviation', '3pl_v_001', '3pl_v_002', '3pl_v_003', '3pl_v_004',\n",
       "       'customs_procedures_CRF', 'customs_procedures_DTD',\n",
       "       'customs_procedures_DTP', 'material_handling_c0.0',\n",
       "       'material_handling_c1.0', 'material_handling_c2.0',\n",
       "       'material_handling_c3.0', 'material_handling_c4.0',\n",
       "       'material_handling_c5.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_target_int = orders_target * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training - test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(orders_features, orders_target_int, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "Using cpu:0 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8048780487804879"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = transformer_prediction_interface.TabPFNClassifier(device='cpu', N_ensemble_configurations=64)\n",
    "model.fit(X_train, y_train, overwrite_warning=True)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 11, 30, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, model.predict(X_test)).ravel()\n",
    "tn, tp, fn, fp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('datathon-fme2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a5f1cad13e83ff8f38af6883a908047d62aca5621397592ff06c4814667afdd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
